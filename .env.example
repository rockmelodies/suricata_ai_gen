# =============================================
# LLM 通用配置
# =============================================
# 支持的 provider:
# - LiteLLM 适配器: openai, gemini, claude, qwen, deepseek, zhipu, moonshot, ollama
# - 原生适配器: baidu, minimax, doubao, 360
LLM_PROVIDER=360

# API 密钥
LLM_API_KEY=your_api_key_here

# 模型名称（留空使用 provider 默认模型）
# OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
# Gemini: gemini-2.0-flash, gemini-1.5-pro
# Claude: claude-3-5-sonnet-20241022, claude-3-haiku-20240307
# Qwen: qwen-turbo, qwen-plus, qwen-max
# DeepSeek: deepseek-chat, deepseek-coder
# Zhipu: glm-4-flash, glm-4
# Moonshot: moonshot-v1-8k, moonshot-v1-32k
# Ollama: llama3, codellama, qwen2.5, deepseek-coder
# 360: 360gpt-pro, 360gpt-turbo
LLM_MODEL=360gpt-pro

# 自定义 API 端点（API 中转站，可选）
# 示例: https://your-proxy.com/v1
LLM_BASE_URL=https://api.360.cn/v1

# 请求超时时间（秒）
LLM_TIMEOUT=150

# 生成温度（0-1，越低越确定性）
LLM_TEMPERATURE=0.1

# 最大生成 Token 数
LLM_MAX_TOKENS=4096

# =============================================
# 数据库配置
# =============================================
DB_PATH=./suricata_rules.db

# =============================================
# Suricata 配置 (Linux/Kali)
# =============================================
SURICATA_RULES_DIR=/var/lib/suricata/rules
SURICATA_CONFIG=/etc/suricata/suricata.yaml
SURICATA_LOG_DIR=/var/log/suricata

# =============================================
# PCAP 目录配置
# =============================================
PCAP_DIR=uploads

# =============================================
# Flask 配置
# =============================================
FLASK_DEBUG=False
FLASK_HOST=0.0.0.0
FLASK_PORT=5000